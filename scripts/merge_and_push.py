import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import duckdb
import glob
import datetime
import argparse
import shutil
import pandas as pd
import baostock as bs # ç”¨äºè·å–è‚¡ç¥¨åç§°åˆ—è¡¨
from utils.hf_manager import HFManager
from utils.qc import QualityControl

def get_stock_list_with_names():
    """è·å–å¸¦åç§°çš„è‚¡ç¥¨åˆ—è¡¨"""
    print("ğŸ“‹ Fetching stock list metadata...")
    try:
        bs.login()
        # è·å–æœ€è¿‘äº¤æ˜“æ—¥çš„è‚¡ç¥¨åˆ—è¡¨
        date = datetime.datetime.now().strftime("%Y-%m-%d")
        # ç®€å•å›æº¯æŸ¥æ‰¾æœ‰æ•°æ®çš„ä¸€å¤©
        for i in range(10):
            d = (datetime.datetime.now() - datetime.timedelta(days=i)).strftime("%Y-%m-%d")
            rs = bs.query_all_stock(day=d)
            if rs.error_code == '0' and len(rs.data) > 0:
                break
        
        data = []
        while rs.next():
            data.append(rs.get_row_data())
        bs.logout()
        
        if data:
            df = pd.DataFrame(data, columns=["code", "tradeStatus", "code_name"])
            # è¿‡æ»¤åªç•™ä¸ªè‚¡
            df = df[df['code'].str.startswith(('sh.', 'sz.', 'bj.'))]
            return df
    except Exception as e:
        print(f"âš ï¸ Failed to fetch stock list: {e}")
    
    return pd.DataFrame()

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", type=str, default="hf", choices=["hf", "release"])
    parser.add_argument("--year", type=int, default=0)
    args = parser.parse_args()
    
    # 1. åˆå§‹åŒ– QC
    qc = QualityControl()
    
    # 2. åˆå§‹åŒ– DuckDB
    print("ğŸ¦† Initializing DuckDB...")
    con = duckdb.connect()
    con.execute("SET memory_limit='5GB'")
    con.execute("SET temp_directory='duckdb_temp.tmp'")
    
    # 3. æ³¨å†Œè§†å›¾
    k_files = glob.glob("all_artifacts/kline_part_*.parquet")
    f_files = glob.glob("all_artifacts/flow_part_*.parquet")
    sec_k_files = glob.glob("all_artifacts/sector_kline_full.parquet")
    
    if k_files:
        con.execute(f"CREATE OR REPLACE VIEW v_kline AS SELECT * FROM read_parquet({k_files}, union_by_name=True)")
    else:
        con.execute("CREATE OR REPLACE VIEW v_kline AS SELECT * FROM read_parquet([], schema={'date': 'VARCHAR', 'code': 'VARCHAR'})")

    if f_files:
        con.execute(f"CREATE OR REPLACE VIEW v_flow AS SELECT * FROM read_parquet({f_files}, union_by_name=True)")
    else:
        con.execute("CREATE OR REPLACE VIEW v_flow AS SELECT * FROM read_parquet([], schema={'date': 'VARCHAR', 'code': 'VARCHAR'})")

    if sec_k_files:
        con.execute(f"CREATE OR REPLACE VIEW v_sec_k AS SELECT * FROM read_parquet('{sec_k_files[0]}')")
    else:
        con.execute("CREATE OR REPLACE VIEW v_sec_k AS SELECT * FROM read_parquet([], schema={'date': 'VARCHAR', 'code': 'VARCHAR'})")

    os.makedirs("output", exist_ok=True)
    targets = {}

    # === æ–°å¢ï¼šç”Ÿæˆå…ƒæ•°æ®åˆ—è¡¨æ–‡ä»¶ ===
    
    # A. è‚¡ç¥¨åˆ—è¡¨ (stock_list.parquet)
    df_stocks = get_stock_list_with_names()
    if not df_stocks.empty:
        p = "output/stock_list.parquet"
        df_stocks.to_parquet(p, index=False)
        targets[p] = "stock_list.parquet"
        print("âœ… Generated: stock_list.parquet")

    # B. æ¿å—åˆ—è¡¨ (sector_list.parquet)
    if sec_k_files:
        # ä»æ¿å—Kçº¿ä¸­æå–å»é‡åçš„æ¿å—ä¿¡æ¯
        con.execute("COPY (SELECT DISTINCT code, name, type FROM v_sec_k ORDER BY type, code) TO 'output/sector_list.parquet' (FORMAT 'PARQUET')")
        targets['output/sector_list.parquet'] = "sector_list.parquet"
        print("âœ… Generated: sector_list.parquet")

    # 4. ç¡®å®šå¹´ä»½è¿›è¡Œåˆ‡åˆ†
    if args.year == 9999:
        current_year = datetime.datetime.now().year
        years = range(2005, current_year)
    elif args.year > 0:
        years = [args.year]
    else:
        years = [datetime.datetime.now().year]

    # 5. å¾ªç¯åˆ‡åˆ† + é€ä¸ªè´¨æ£€
    for y in years:
        print(f"ğŸ”ª Processing Year {y}...")
        start_date = f"{y}-01-01"
        end_date = f"{y}-12-31"
        
        tasks = [
            ("v_kline", f"stock_kline_{y}.parquet", ["close", "volume"]),
            ("v_flow", f"stock_money_flow_{y}.parquet", ["net_amount"]),
            ("v_sec_k", f"sector_kline_{y}.parquet", ["close"])
        ]
        
        for view_name, out_name, check_cols in tasks:
            out_path = f"output/{out_name}"
            
            # åªæœ‰å½“è§†å›¾æœ‰æ•°æ®æ—¶æ‰æ‰§è¡Œ COPY
            # (ç®€å•çš„åˆ¤ç©ºé€»è¾‘ï¼šcount(*))
            try:
                count = con.execute(f"SELECT count(*) FROM {view_name} WHERE date >= '{start_date}' AND date <= '{end_date}'").fetchone()[0]
                if count == 0:
                    continue
            except: continue

            query = f"""
            COPY (
                SELECT * FROM {view_name}
                WHERE date >= '{start_date}' AND date <= '{end_date}'
                ORDER BY code, date
            ) TO '{out_path}' (FORMAT 'PARQUET', COMPRESSION 'ZSTD');
            """
            
            try:
                con.execute(query)
                if os.path.exists(out_path):
                    df_check = pd.read_parquet(out_path)
                    if not df_check.empty:
                        qc.check_dataframe(df_check, out_name, check_cols)
                        targets[out_path] = out_name
            except Exception as e:
                print(f"âŒ Error processing {out_name}: {e}")

        # C. æ¿å—æˆåˆ†è¡¨ (sector_constituents_YYYY.parquet)
        sec_c_files = glob.glob("all_artifacts/sector_constituents_latest.parquet")
        if sec_c_files:
            c_out = f"output/sector_constituents_{y}.parquet"
            try:
                shutil.copy(sec_c_files[0], c_out)
                targets[c_out] = f"sector_constituents_{y}.parquet"
            except: pass

    # 6. ä¿å­˜æ±‡æ€»æŠ¥å‘Š
    print("ğŸ“ Generating QC Report...")
    qc.save_report("output/qc_report.json")
    with open("output/qc_summary.md", "w") as f:
        f.write(qc.get_summary_md())
        
    targets["output/qc_report.json"] = "qc_report.json"
    targets["output/qc_summary.md"] = "qc_summary.md"

    # 7. ä¸Šä¼  HF
    if args.mode == "hf":
        if os.getenv("HF_TOKEN"):
            print(f"ğŸš€ Uploading {len(targets)} files to HuggingFace...")
            hf = HFManager(os.getenv("HF_TOKEN"), os.getenv("HF_REPO"))
            for local, remote in targets.items():
                hf.upload_file(local, remote)
        else:
            print("âš ï¸ HF_TOKEN not set, skipping upload.")

if __name__ == "__main__":
    main()
