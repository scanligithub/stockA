import sys
import os

# === å…³é”®ä¿®å¤ï¼šå°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ python path ===
# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½• (scripts) çš„ä¸Šä¸€çº§ç›®å½• (é¡¹ç›®æ ¹ç›®å½•)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
import glob
import datetime
import argparse
from utils.cleaner import DataCleaner
from utils.qc import QualityControl
from utils.hf_manager import HFManager

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", type=str, default="hf", choices=["hf", "release"])
    parser.add_argument("--year", type=int, default=0)
    args = parser.parse_args()
    
    year = args.year if args.year > 0 else datetime.datetime.now().year
    
    # 1. åˆå¹¶ä¸ªè‚¡åˆ†ç‰‡
    print("ğŸ“¦ Merging parts...")
    k_files = glob.glob("all_artifacts/kline_part_*.parquet")
    f_files = glob.glob("all_artifacts/flow_part_*.parquet")
    
    df_k = pd.concat([pd.read_parquet(f) for f in k_files]) if k_files else pd.DataFrame()
    df_f = pd.concat([pd.read_parquet(f) for f in f_files]) if f_files else pd.DataFrame()
    
    # 2. è¯»å–æ¿å—æ•°æ®
    # æ¿å—æ•°æ®ç”± fetch_sector ç”Ÿæˆï¼Œæ”¾åœ¨ artifacts é‡Œ
    sec_k_file = glob.glob("all_artifacts/sector_kline_full.parquet")
    sec_c_file = glob.glob("all_artifacts/sector_constituents_latest.parquet")
    
    # æ³¨æ„ï¼šfetch_sector å¯èƒ½æ²¡ç”Ÿæˆæ–‡ä»¶ï¼ˆå¦‚æœæ²¡é…ä»£ç†ï¼‰ï¼Œæ‰€ä»¥è¦åˆ¤ç©º
    df_sec_k = pd.read_parquet(sec_k_file[0]) if sec_k_file else pd.DataFrame()
    df_sec_c = pd.read_parquet(sec_c_file[0]) if sec_c_file else pd.DataFrame()
    
    # 3. æŒ‰å¹´ä»½è¿‡æ»¤ (å¯¹äº Sectorï¼Œä¸‹è½½çš„æ˜¯å…¨é‡ï¼Œéœ€è¦åˆ‡åˆ†)
    start_date = f"{year}-01-01"
    end_date = f"{year}-12-31"
    
    # ä¸ªè‚¡æ•°æ®å·²ç»æ˜¯æŒ‰å¹´ä»½ä¸‹è½½çš„ï¼Œä¸éœ€è¦å† filter
    # ä»…å¯¹ Sector æ•°æ®è¿›è¡Œå¹´ä»½è¿‡æ»¤
    if not df_sec_k.empty:
        df_sec_k = df_sec_k[(df_sec_k['date'] >= start_date) & (df_sec_k['date'] <= end_date)]

    # 4. æ¸…æ´—
    print("ğŸ§¹ Cleaning data...")
    cleaner = DataCleaner()
    df_k = cleaner.clean_stock_kline(df_k)
    df_f = cleaner.clean_money_flow(df_f)
    # Sectoræ•°æ®åœ¨ fetch é˜¶æ®µå·²æ¸…æ´—
    
    # 5. è´¨æ£€
    print("ğŸ” Quality check...")
    qc = QualityControl()
    qc.check_dataframe(df_k, "stock_kline", ["close", "volume"])
    qc.check_dataframe(df_f, "money_flow", ["net_amount"])
    qc.save_report("qc_report.json")
    with open("qc_summary.md", "w") as f: f.write(qc.get_summary_md())

    # 6. ä¿å­˜æœ€ç»ˆæ–‡ä»¶
    os.makedirs("output", exist_ok=True)
    targets = {}
    
    if not df_k.empty:
        p = f"output/stock_kline_{year}.parquet"
        df_k.to_parquet(p, index=False)
        targets[p] = f"stock_kline_{year}.parquet"
        print(f"âœ… Generated: {p} ({len(df_k)} rows)")
        
    if not df_f.empty:
        p = f"output/stock_money_flow_{year}.parquet"
        df_f.to_parquet(p, index=False)
        targets[p] = f"stock_money_flow_{year}.parquet"
        print(f"âœ… Generated: {p} ({len(df_f)} rows)")
        
    if not df_sec_k.empty:
        p = f"output/sector_kline_{year}.parquet"
        df_sec_k.to_parquet(p, index=False)
        targets[p] = f"sector_kline_{year}.parquet"
        print(f"âœ… Generated: {p} ({len(df_sec_k)} rows)")
        
    if not df_sec_c.empty:
        p = f"output/sector_constituents_{year}.parquet"
        df_sec_c.to_parquet(p, index=False)
        targets[p] = f"sector_constituents_{year}.parquet"
        print(f"âœ… Generated: {p} ({len(df_sec_c)} rows)")

    # 7. ä¸Šä¼  HF
    if args.mode == "hf":
        if os.getenv("HF_TOKEN"):
            print("ğŸš€ Uploading to HuggingFace...")
            hf = HFManager(os.getenv("HF_TOKEN"), os.getenv("HF_REPO"))
            for local, remote in targets.items():
                hf.upload_file(local, remote)
        else:
            print("âš ï¸ HF_TOKEN not found, skipping upload.")

if __name__ == "__main__":
    main()
